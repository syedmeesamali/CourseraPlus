{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 on Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [\n",
    "'If the Main Appointment is terminated for any reason or if under the terms of the Main Appointment the '\n",
    "'Consultant is instructed to remove the Sub-Consultant from involvement in the Project, then the Agreement ' \n",
    "'shall automatically terminate. '\n",
    "'The Consultant shall notify the Sub-Consultant as soon as it is reasonably able to do so.',\n",
    "\n",
    "'The Consultant may terminate this Agreement at any time on giving seven (7) Days '\n",
    "'notice in writing to the Sub-Consultant.',\n",
    "\n",
    "'If either party becomes insolvent or bankrupt then the other party may immediately '\n",
    "'terminate the Agreement by notice in writing.',\n",
    "\n",
    "'Upon suspension or termination of the Agreement, '\n",
    "'the Sub-Consultant shall immediately take steps to bring the performance of the Sub-Consultancy '\n",
    "'Services to an end in an orderly manner. The Sub-Consultant shall deliver up to '\n",
    "'the Consultant all documents (including electronic documents) relating to the Project including any Materials.',\n",
    "\n",
    "'Following termination of this Agreement the Consultant may carry out the Sub-Consultancy Services '\n",
    "'itself or may engage others to carry out the Sub-Consultancy Services and the Sub-Consultant shall '\n",
    "'have no claim against the Consultant for so doing.'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Prepare the dataset\n",
    "# Assume that you have a list of sentences called `train_sentences`\n",
    "# Convert the sentences to input ids and attention masks\n",
    "input_ids = [tokenizer.encode(sent, add_special_tokens = True) for sent in train_sentences]\n",
    "attention_masks = [[float(i > 0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids)\n",
    "attention_masks = tf.keras.preprocessing.sequence.pad_sequences(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(attention_masks[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-tune the model on the dataset\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_epochs = 200 (With GPU PC)\n",
    "num_epochs = 20\n",
    "for _ in range(num_epochs):\n",
    "    output = model(input_ids, attention_mask = attention_masks)\n",
    "    #loss = model.config.lm_coef * output[0].mean()\n",
    "    loss = loss_fn(output[0].view(-1, output[0].size(-1)), input_ids.view(-1).long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('../2_ChatGPT/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
