{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syedm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=80, break_long_words=False, break_on_hyphens=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classifying whole sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentence:\n",
      "the flights were on time in sydney and connecting flights in singapore. The\n",
      "organization to cope with COVID is very strict\n",
      "\n",
      " This sentence is classified with a NEGATIVE sentiment\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the flights were on time in sydney and connecting flights in singapore. The organization to cope with COVID is very strict\"\n",
    "classifier = pipeline('text-classification', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "c = classifier(sentence)\n",
    "print(\"\\n Sentence:\")\n",
    "print(wrapper.fill(sentence))\n",
    "print(f\"\\n This sentence is classified with a {c[0]['label']} sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "Qatar Airways is one of the world's leading airlines, based in Doha, Qatar. As\n",
      "of September 2021, the airline had a fleet of 136 aircraft, consisting of\n",
      "various types, such as Airbus A350, Airbus A380, Boeing 777, and Boeing 787\n",
      "Dreamliner. The airline is committed to providing its passengers with the\n",
      "highest level of service and comfort, and its modern fleet is equipped with\n",
      "state-of-the-art amenities and technology to ensure a comfortable and safe\n",
      "journey.\n",
      "\n",
      " Question\n",
      "How many planes does qatar airways have?\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Qatar Airways is one of the world's leading airlines, based in Doha, Qatar. As of September 2021, the airline had a fleet of 136 aircraft, consisting of various types, such as Airbus A350, Airbus A380, Boeing 777, and Boeing 787 Dreamliner. The airline is committed to providing its passengers with the highest level of service and comfort, and its modern fleet is equipped with state-of-the-art amenities and technology to ensure a comfortable and safe journey.\"\n",
    "\n",
    "question = \"How many planes does qatar airways have?\"\n",
    "print(\"Text: \")\n",
    "print(wrapper.fill(text1))\n",
    "print(\"\\n Question\")\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: \n",
      "How many planes does qatar airways have?\n",
      "\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'136'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')\n",
    "print(\"\\nQuestion: \")\n",
    "print(question + \"\\n\")\n",
    "print('Answer: ')\n",
    "a = qa(context = text1, question=question)\n",
    "a['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "We introduced a framework for achieving strong natural language understanding\n",
      "with a single task-agnostic model through generative pre-training and\n",
      "discriminative fine-tuning. By pre-training on a diverse corpus with long\n",
      "stretches of contiguous text our model acquires significant world knowledge and\n",
      "ability to process long-range dependencies which are then successfully\n",
      "transferred to solving discriminative tasks such as question answering, semantic\n",
      "similarity assessment, entailment determination, and text classification,\n",
      "improving the state of the art on 9 of the 12 datasets we study. Using\n",
      "unsupervised (pre-)training to boost performance on discriminative tasks has\n",
      "long been an important goal of Machine Learning research. Our work suggests that\n",
      "achieving significant performance gains is indeed possible, and offers hints as\n",
      "to what models (Transformers) and data sets (text with long range dependencies)\n",
      "work best with this approach. We hope that this will help enable new research\n",
      "into unsupervised learning, for both natural language understanding and other\n",
      "domains, further improving our understanding of how and when unsupervised\n",
      "learning works.\n",
      "\n",
      " Question\n",
      "How many datasets were studied?\n"
     ]
    }
   ],
   "source": [
    "text2 = \"We introduced a framework for achieving strong natural language understanding with a single task-agnostic model through generative pre-training and discriminative fine-tuning. By pre-training on a diverse corpus with long stretches of contiguous text our model acquires significant world knowledge and ability to process long-range dependencies which are then successfully transferred to solving discriminative tasks such as question answering, semantic similarity assessment, entailment determination, and text classification, improving the state of the art on 9 of the 12 datasets we study. Using unsupervised (pre-)training to boost performance on discriminative tasks has long been an important goal of Machine Learning research. Our work suggests that achieving significant performance gains is indeed possible, and offers hints as to what models (Transformers) and data sets (text with long range dependencies) work best with this approach. We hope that this will help enable new research into unsupervised learning, for both natural language understanding and other domains, further improving our understanding of how and when unsupervised learning works.\"\n",
    "\n",
    "q2 = \"How many datasets were studied?\"\n",
    "print(\"Text: \")\n",
    "print(wrapper.fill(text2))\n",
    "print(\"\\n Question\")\n",
    "print(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: \n",
      "How many datasets were studied?\n",
      "\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'12'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nQuestion: \")\n",
    "print(q2 + \"\\n\")\n",
    "print('Answer: ')\n",
    "a2 = qa(context = text2, question=question)\n",
    "a2['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
