{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis - Amazon baby data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "products = pd.read_csv(f\"D:/Docs/amazon_baby.csv\")\n",
    "#products = pd.read_csv(f\"D:/SYED/data/amazon_baby.csv\")\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the NAN values in review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products['review'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "products['review_clean'] = products['review'].apply(lambda x: x.translate(str.maketrans('', '', \n",
    "                           string.punctuation)))\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rating of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More than 3 is +1 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products['review'][27401]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data as test and train\n",
    "* `train-idx.json` for Training data\n",
    "* `test-idx.json` for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_indices = pd.read_json(f\"D:/repos/CourseraPlus/1_ML_Combined_Courses/Course/Week-2/train-idx.json\")\n",
    "train_data = pd.DataFrame(products, index = train_data_indices[0])\n",
    "test_data_indices = pd.read_json(f\"D:/repos/CourseraPlus/1_ML_Combined_Courses/Course/Week-2/test-idx.json\")\n",
    "test_data = pd.DataFrame(products, index = test_data_indices[0])\n",
    "print(\"Train set: \" + str(train_data.shape))\n",
    "print(\"Test set: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all the NaN before carrying out training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(subset = [\"name\"], inplace=True)\n",
    "train_data.isnull().values.sum()\n",
    "test_data.dropna(subset = [\"name\"], inplace=True)\n",
    "test_data.isnull().values.sum()\n",
    "print(\"Train set: \" + str(train_data.shape))\n",
    "print(\"Test set: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern = r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "print(\"Train matrix: \" + str(train_matrix.shape))\n",
    "print(\"Test matrix: \" + str(test_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sentiment_model = LogisticRegression(random_state=0).fit(train_matrix, train_data['sentiment'])\n",
    "zero_elem = (sentiment_model.coef_ > 0).sum()\n",
    "less_elem = (sentiment_model.coef_ <= 0).sum()\n",
    "total_val = zero_elem + less_elem\n",
    "print(\"Co-efficients with value more than 0: \" + str(zero_elem) + \" out of \" + str(total_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data = test_data[45:50]\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores_sample = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function based on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_score(input_array):\n",
    "    result = []\n",
    "    for x in input_array:\n",
    "        if x >= 0:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "    return result\n",
    "check_score(scores_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = sentiment_model.predict(test_matrix)\n",
    "final_scores_data = vectorizer.transform(test_data['review_clean'])\n",
    "final_score = sentiment_model.decision_function(final_scores_data)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_score, columns = ['Score'])\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(test_set.shape)\n",
    "print(test_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test_set\n",
    "df_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.concat([df, test_set])\n",
    "df2 = pd.concat([df, test_set], axis = 1)\n",
    "df_export = df2.sort_values(by='Score', ascending=False)\n",
    "df_export.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data (Top & Bot 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top = df_export.head(20)\n",
    "#df_top.to_csv('top20.csv')\n",
    "df_bottom = df_export.tail(20)\n",
    "#df_bottom.to_csv('bottom20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scores dataframe shape: \" + str(df.shape))\n",
    "print(\"Test data sentiment as reference shape: \" + str(test_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sentiment_model = sentiment_model.score(final_scores_data, test_set['sentiment'].values)\n",
    "print(\"Sentiment model accuracy:\\n\" + str(accuracy_sentiment_model * 100) + \" percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary = significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_set['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_set['review_clean'])\n",
    "print(\"Train matrix special: \" + str(train_matrix_word_subset.shape))\n",
    "print(\"Test matrix special: \" + str(test_matrix_word_subset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Log-Reg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = LogisticRegression(random_state=0).fit(train_matrix_word_subset, train_set['sentiment'])\n",
    "zero_elem_simple = (simple_model.coef_ > 0).sum()\n",
    "print(zero_elem_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the coefficients for 20 words used in model\n",
    "simple_model.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
