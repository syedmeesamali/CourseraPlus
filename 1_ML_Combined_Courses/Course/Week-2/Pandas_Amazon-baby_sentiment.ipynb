{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Amazon baby data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   name    183213 non-null  object\n",
      " 1   review  182702 non-null  object\n",
      " 2   rating  183531 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#products = pd.read_csv(f\"D:/Docs/amazon_baby.csv\")\n",
    "products = pd.read_csv(f\"D:/SYED/data/amazon_baby.csv\")\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the NAN values in review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products['review'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>These flannel wipes are OK but in my opinion n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "0             Planetwise Flannel Wipes   \n",
       "1                Planetwise Wipe Pouch   \n",
       "2  Annas Dream Full Quilt with 2 Shams   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  These flannel wipes are OK, but in my opinion ...       3   \n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "\n",
       "                                        review_clean  \n",
       "0  These flannel wipes are OK but in my opinion n...  \n",
       "1  it came early and was not disappointed i love ...  \n",
       "2  Very soft and comfortable and warmer than it l...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "products['review_clean'] = products['review'].apply(lambda x: x.translate(str.maketrans('', '', \n",
    "                           string.punctuation)))\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rating of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "\n",
       "                                        review_clean  \n",
       "1  it came early and was not disappointed i love ...  \n",
       "2  Very soft and comfortable and warmer than it l...  \n",
       "3  This is a product well worth the purchase  I h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More than 3 is +1 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love this product.Simple but does the job great.Very easy to attach.I really have nothing bad to say about it.My baby is now protected from the sun.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products['review'][27401]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data as test and train\n",
    "* `train-idx.json` for Training data\n",
    "* `test-idx.json` for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (133416, 5)\n",
      "Test set: (33336, 5)\n"
     ]
    }
   ],
   "source": [
    "train_data_indices = pd.read_json(f\"D:/repos/CourseraPlus/1_ML_Combined_Courses/Course/Week-2/train-idx.json\")\n",
    "train_data = pd.DataFrame(products, index = train_data_indices[0])\n",
    "test_data_indices = pd.read_json(f\"D:/repos/CourseraPlus/1_ML_Combined_Courses/Course/Week-2/test-idx.json\")\n",
    "test_data = pd.DataFrame(products, index = test_data_indices[0])\n",
    "print(\"Train set: \" + str(train_data.shape))\n",
    "print(\"Test set: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all the NaN before carrying out training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (121011, 5)\n",
      "Test set: (30209, 5)\n"
     ]
    }
   ],
   "source": [
    "train_data.dropna(subset = [\"name\"], inplace=True)\n",
    "train_data.isnull().values.sum()\n",
    "test_data.dropna(subset = [\"name\"], inplace=True)\n",
    "test_data.isnull().values.sum()\n",
    "print(\"Train set: \" + str(train_data.shape))\n",
    "print(\"Test set: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix: (121011, 113128)\n",
      "Test matrix: (30209, 113128)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern = r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "print(\"Train matrix: \" + str(train_matrix.shape))\n",
    "print(\"Test matrix: \" + str(test_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-efficients with value more than 0: 83399 out of 113128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SYED\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sentiment_model = LogisticRegression(random_state=0).fit(train_matrix, train_data['sentiment'])\n",
    "zero_elem = (sentiment_model.coef_ > 0).sum()\n",
    "less_elem = (sentiment_model.coef_ <= 0).sum()\n",
    "total_val = zero_elem + less_elem\n",
    "print(\"Co-efficients with value more than 0: \" + str(zero_elem) + \" out of \" + str(total_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ive tried this for almost 6 months at different points of our kid teething and shes just not that into this Its really heavy for a baby When I would hold the vibrating setting on my kid would watch for a bit and even try it but just seemed bored with it and would move on The yellow part also attracts dust and fiber out of the air like a magnet It is ALWAYS dirty Im not that particular when it comes to dirt and baby stuff but it grosses me out Its also only wire clean so its a more high maintenance toy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data[45:50]\n",
    "sample_test_data['review_clean'][235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.87526241 -1.92773272  7.6149094   2.29150689  4.28450617]\n"
     ]
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores_sample = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function based on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, -1, 1, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_score(input_array):\n",
    "    result = []\n",
    "    for x in input_array:\n",
    "        if x >= 0:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "    return result\n",
    "check_score(scores_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97967287 0.12700175 0.9995072  0.9081712  0.98640689]\n"
     ]
    }
   ],
   "source": [
    "prob_val = sentiment_model.predict_proba(sample_test_matrix)\n",
    "print(prob_val[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full data sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30209, 1)\n",
      "Index(['Score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#predictions = sentiment_model.predict(test_matrix)\n",
    "final_scores_data = vectorizer.transform(test_data['review_clean'])\n",
    "final_score = sentiment_model.decision_function(final_scores_data)\n",
    "df = pd.DataFrame(final_score, columns = ['Score'])\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20952</th>\n",
       "      <td>71.342360</td>\n",
       "      <td>Joovy Scooter Single Stroller Greenie</td>\n",
       "      <td>***I've posted an UPDATE at the end***First, l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ive posted an UPDATE at the endFirst let me st...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22392</th>\n",
       "      <td>57.554025</td>\n",
       "      <td>Zooper 2011 Waltz Standard Stroller, Flax Brown</td>\n",
       "      <td>I did a TON of research before I purchased thi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I did a TON of research before I purchased thi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>53.675176</td>\n",
       "      <td>Ubbi Cloth Diaper Pail Liner</td>\n",
       "      <td>(updated 3.22.13) After extensive research, tr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>updated 32213 After extensive research trial a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18044</th>\n",
       "      <td>44.201512</td>\n",
       "      <td>Infantino Wrap and Tie Baby Carrier, Black Blu...</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9166</th>\n",
       "      <td>41.352585</td>\n",
       "      <td>Joovy Zoom 360 Swivel Wheel Jogging Stroller, ...</td>\n",
       "      <td>The joovy zoom 360 was the perfect solution fo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The joovy zoom 360 was the perfect solution fo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Score                                               name  \\\n",
       "20952  71.342360              Joovy Scooter Single Stroller Greenie   \n",
       "22392  57.554025    Zooper 2011 Waltz Standard Stroller, Flax Brown   \n",
       "28615  53.675176                       Ubbi Cloth Diaper Pail Liner   \n",
       "18044  44.201512  Infantino Wrap and Tie Baby Carrier, Black Blu...   \n",
       "9166   41.352585  Joovy Zoom 360 Swivel Wheel Jogging Stroller, ...   \n",
       "\n",
       "                                                  review  rating  \\\n",
       "20952  ***I've posted an UPDATE at the end***First, l...     5.0   \n",
       "22392  I did a TON of research before I purchased thi...     5.0   \n",
       "28615  (updated 3.22.13) After extensive research, tr...     5.0   \n",
       "18044  I bought this carrier when my daughter was abo...     5.0   \n",
       "9166   The joovy zoom 360 was the perfect solution fo...     5.0   \n",
       "\n",
       "                                            review_clean  sentiment  \n",
       "20952  Ive posted an UPDATE at the endFirst let me st...        1.0  \n",
       "22392  I did a TON of research before I purchased thi...        1.0  \n",
       "28615  updated 32213 After extensive research trial a...        1.0  \n",
       "18044  I bought this carrier when my daughter was abo...        1.0  \n",
       "9166   The joovy zoom 360 was the perfect solution fo...        1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = test_data\n",
    "df_test.reset_index(drop = True, inplace = True)\n",
    "df2 = pd.concat([df, df_test], axis = 1)\n",
    "df_export = df2.sort_values(by='Score', ascending=False)\n",
    "df_export.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data (Top & Bot 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top = df_export.head(20)\n",
    "df_top.to_csv('top20.csv')\n",
    "df_bottom = df_export.tail(20)\n",
    "df_bottom.to_csv('bottom20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy - Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores dataframe shape: (30209, 1)\n",
      "Test data sentiment as reference shape: (30209, 5)\n",
      "Sentiment model accuracy:\n",
      "0.9323711476712238\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores dataframe shape: \" + str(df.shape))\n",
    "print(\"Test data sentiment as reference shape: \" + str(test_data.shape))\n",
    "accuracy_sentiment_model = sentiment_model.score(final_scores_data, test_data['sentiment'].values)\n",
    "print(\"Sentiment model accuracy:\\n\" + str(accuracy_sentiment_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix special: (121011, 20)\n",
      "Test matrix special: (30209, 20)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary = significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])\n",
    "print(\"Train matrix special: \" + str(train_matrix_word_subset.shape))\n",
    "print(\"Test matrix special: \" + str(test_matrix_word_subset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Log-Reg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "simple_model = LogisticRegression(random_state=0).fit(train_matrix_word_subset, train_data['sentiment'])\n",
    "zero_elem_simple = (simple_model.coef_ > 0).sum()\n",
    "print(zero_elem_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113128"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = simple_model.coef_\n",
    "arr2 = sentiment_model.coef_\n",
    "arr1 = arr1.reshape(-1, 1)\n",
    "arr2 = arr2.reshape(-1, 1)\n",
    "list1 = arr1.tolist()\n",
    "list2 = arr2.tolist()\n",
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '000', '0001', ..., 'zzzs', 'zzzzzs', 'zzzzzzz'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-efficient dictionary for significant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the coefficients for 20 words used in model\n",
    "output_dict = dict(zip(significant_words, list1))\n",
    "setiment_dict = dict(zip(vectorizer.get_feature_names_out(), list2))\n",
    "#print(setiment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare two dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Small</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>[1.3621112869582248]</td>\n",
       "      <td>[1.4249338679594974]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>[0.9261265484135819]</td>\n",
       "      <td>[1.1619400587323814]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>easy</td>\n",
       "      <td>[1.183965816837404]</td>\n",
       "      <td>[1.2366282248611826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>[0.12316404245309258]</td>\n",
       "      <td>[0.11579835774697814]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little</td>\n",
       "      <td>[0.49928669653559826]</td>\n",
       "      <td>[0.6105697786990087]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perfect</td>\n",
       "      <td>[1.5162437806348728]</td>\n",
       "      <td>[1.4768290290053212]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loves</td>\n",
       "      <td>[1.7448865646572738]</td>\n",
       "      <td>[1.4299193249640445]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>[0.47048103843759737]</td>\n",
       "      <td>[0.5124721886553975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>[0.18216586532103662]</td>\n",
       "      <td>[0.35815397843685565]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>car</td>\n",
       "      <td>[0.09178103094711185]</td>\n",
       "      <td>[0.2645255293237002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>broke</td>\n",
       "      <td>[-1.6683903792219996]</td>\n",
       "      <td>[-1.0529861909478286]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>less</td>\n",
       "      <td>[-0.1882884700554159]</td>\n",
       "      <td>[-0.23805025889936543]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>even</td>\n",
       "      <td>[-0.5207619982194437]</td>\n",
       "      <td>[-0.43792643767034434]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>waste</td>\n",
       "      <td>[-2.0133582844709257]</td>\n",
       "      <td>[-1.863778326293303]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>[-2.355010892742177]</td>\n",
       "      <td>[-1.6155116280717339]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>work</td>\n",
       "      <td>[-0.637240726369638]</td>\n",
       "      <td>[-0.47614370035617065]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>product</td>\n",
       "      <td>[-0.310176454433061]</td>\n",
       "      <td>[-0.24407498111710815]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>money</td>\n",
       "      <td>[-0.8847617799297401]</td>\n",
       "      <td>[-0.9035985174633094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>would</td>\n",
       "      <td>[-0.33758629282141006]</td>\n",
       "      <td>[-0.2497928730585927]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>return</td>\n",
       "      <td>[-2.020954522474437]</td>\n",
       "      <td>[-1.1683487493482738]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word                   Small               Sentiment\n",
       "0           love    [1.3621112869582248]    [1.4249338679594974]\n",
       "1          great    [0.9261265484135819]    [1.1619400587323814]\n",
       "2           easy     [1.183965816837404]    [1.2366282248611826]\n",
       "3            old   [0.12316404245309258]   [0.11579835774697814]\n",
       "4         little   [0.49928669653559826]    [0.6105697786990087]\n",
       "5        perfect    [1.5162437806348728]    [1.4768290290053212]\n",
       "6          loves    [1.7448865646572738]    [1.4299193249640445]\n",
       "7           well   [0.47048103843759737]    [0.5124721886553975]\n",
       "8           able   [0.18216586532103662]   [0.35815397843685565]\n",
       "9            car   [0.09178103094711185]    [0.2645255293237002]\n",
       "10         broke   [-1.6683903792219996]   [-1.0529861909478286]\n",
       "11          less   [-0.1882884700554159]  [-0.23805025889936543]\n",
       "12          even   [-0.5207619982194437]  [-0.43792643767034434]\n",
       "13         waste   [-2.0133582844709257]    [-1.863778326293303]\n",
       "14  disappointed    [-2.355010892742177]   [-1.6155116280717339]\n",
       "15          work    [-0.637240726369638]  [-0.47614370035617065]\n",
       "16       product    [-0.310176454433061]  [-0.24407498111710815]\n",
       "17         money   [-0.8847617799297401]   [-0.9035985174633094]\n",
       "18         would  [-0.33758629282141006]   [-0.2497928730585927]\n",
       "19        return    [-2.020954522474437]   [-1.1683487493482738]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_ndic(src, dest):\n",
    "    result = []\n",
    "    for skey, sval in src.items():\n",
    "        for nkey, nval in dest.items():\n",
    "            if skey == nkey:\n",
    "                result.append([skey, sval, nval])\n",
    "    return result\n",
    "\n",
    "new_list = compare_ndic(output_dict, setiment_dict)\n",
    "df_dict = pd.DataFrame(new_list, columns=['Word', 'Small', 'Sentiment'])\n",
    "df_dict.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare `train` & `test` accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment model accuracy TRAINING data:\n",
      "0.9323711476712238\n",
      "Simple model accuracy TRAINING data:\n",
      "0.8686815187526896\n"
     ]
    }
   ],
   "source": [
    "accuracy_sentiment_model = sentiment_model.score(final_scores_data, test_data['sentiment'].values)\n",
    "print(\"Sentiment model accuracy TRAINING data:\\n\" + str(accuracy_sentiment_model))\n",
    "\n",
    "accuracy_simple_model = simple_model.score(test_matrix_word_subset, test_data['sentiment'].values)\n",
    "print(\"Simple model accuracy TRAINING data:\\n\" + str(accuracy_simple_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    140259\n",
       "-1     26493\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority classifier accuracy should be:\n",
      "0.8411233448474381\n"
     ]
    }
   ],
   "source": [
    "print(\"Majority classifier accuracy should be:\\n\" + str(140259/(140259+26493)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19c641909dbba517c49d9f0678c83bb6138cd8161df841f54650d88c9b22b355"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
