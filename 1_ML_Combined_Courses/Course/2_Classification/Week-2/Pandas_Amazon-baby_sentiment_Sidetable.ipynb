{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Amazon baby data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sidetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   name    183213 non-null  object\n",
      " 1   review  182702 non-null  object\n",
      " 2   rating  183531 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "products = pd.read_csv(f\"D:/Docs/amazon_baby.csv\")\n",
    "#products = pd.read_csv(f\"D:/SYED/data/amazon_baby.csv\")\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function from sidetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "      <th>cumulative_count</th>\n",
       "      <th>cumulative_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>785</td>\n",
       "      <td>0.428463</td>\n",
       "      <td>785</td>\n",
       "      <td>0.428463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple Wishes Hands-Free Breastpump Bra, Pink,...</td>\n",
       "      <td>562</td>\n",
       "      <td>0.306747</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.735210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infant Optics DXR-5 2.4 GHz Digital Video Baby...</td>\n",
       "      <td>561</td>\n",
       "      <td>0.306201</td>\n",
       "      <td>1908</td>\n",
       "      <td>1.041411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby Einstein Take Along Tunes</td>\n",
       "      <td>547</td>\n",
       "      <td>0.298560</td>\n",
       "      <td>2455</td>\n",
       "      <td>1.339970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cloud b Twilight Constellation Night Light, Tu...</td>\n",
       "      <td>520</td>\n",
       "      <td>0.283823</td>\n",
       "      <td>2975</td>\n",
       "      <td>1.623793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32412</th>\n",
       "      <td>&amp;quot;B&amp;quot; Is for Babies (And Booties!) 201...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>183209</td>\n",
       "      <td>99.997817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32413</th>\n",
       "      <td>&amp;quot;A&amp;quot; Soccer Ball Alphabet Letter Name...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>183210</td>\n",
       "      <td>99.998363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32414</th>\n",
       "      <td>#88 Turquoise polka dot baby leg warmers for b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>183211</td>\n",
       "      <td>99.998908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32415</th>\n",
       "      <td>#55 Red &amp;amp; blue stars patriotic leg warmers...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>183212</td>\n",
       "      <td>99.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32416</th>\n",
       "      <td>#1 Adjustable Back Seat Baby Safety Mirror - E...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>183213</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32417 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  count   percent  \\\n",
       "0                       Vulli Sophie the Giraffe Teether    785  0.428463   \n",
       "1      Simple Wishes Hands-Free Breastpump Bra, Pink,...    562  0.306747   \n",
       "2      Infant Optics DXR-5 2.4 GHz Digital Video Baby...    561  0.306201   \n",
       "3                         Baby Einstein Take Along Tunes    547  0.298560   \n",
       "4      Cloud b Twilight Constellation Night Light, Tu...    520  0.283823   \n",
       "...                                                  ...    ...       ...   \n",
       "32412  &quot;B&quot; Is for Babies (And Booties!) 201...      1  0.000546   \n",
       "32413  &quot;A&quot; Soccer Ball Alphabet Letter Name...      1  0.000546   \n",
       "32414  #88 Turquoise polka dot baby leg warmers for b...      1  0.000546   \n",
       "32415  #55 Red &amp; blue stars patriotic leg warmers...      1  0.000546   \n",
       "32416  #1 Adjustable Back Seat Baby Safety Mirror - E...      1  0.000546   \n",
       "\n",
       "       cumulative_count  cumulative_percent  \n",
       "0                   785            0.428463  \n",
       "1                  1347            0.735210  \n",
       "2                  1908            1.041411  \n",
       "3                  2455            1.339970  \n",
       "4                  2975            1.623793  \n",
       "...                 ...                 ...  \n",
       "32412            183209           99.997817  \n",
       "32413            183210           99.998363  \n",
       "32414            183211           99.998908  \n",
       "32415            183212           99.999454  \n",
       "32416            183213          100.000000  \n",
       "\n",
       "[32417 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.stb.freq([\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>318</td>\n",
       "      <td>183531</td>\n",
       "      <td>0.173268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>0</td>\n",
       "      <td>183531</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>0</td>\n",
       "      <td>183531</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        missing   total   percent\n",
       "name        318  183531  0.173268\n",
       "review        0  183531  0.000000\n",
       "rating        0  183531  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.stb.missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the NAN values in review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products['review'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "products['review_clean'] = products['review'].apply(lambda x: x.translate(str.maketrans('', '', \n",
    "                           string.punctuation)))\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rating of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More than 3 is +1 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products['review'][27401]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data as test and train\n",
    "* `train-idx.json` for Training data\n",
    "* `test-idx.json` for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_indices = pd.read_json(f\"D:/repos/CourseraPlus/1_ML_Combined_Courses/Course/Week-2/train-idx.json\")\n",
    "train_data = pd.DataFrame(products, index = train_data_indices[0])\n",
    "test_data_indices = pd.read_json(f\"D:/repos/CourseraPlus/1_ML_Combined_Courses/Course/Week-2/test-idx.json\")\n",
    "test_data = pd.DataFrame(products, index = test_data_indices[0])\n",
    "print(\"Train set: \" + str(train_data.shape))\n",
    "print(\"Test set: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all the NaN before carrying out training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(subset = [\"name\"], inplace=True)\n",
    "train_data.isnull().values.sum()\n",
    "test_data.dropna(subset = [\"name\"], inplace=True)\n",
    "test_data.isnull().values.sum()\n",
    "print(\"Train set: \" + str(train_data.shape))\n",
    "print(\"Test set: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern = r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "print(\"Train matrix: \" + str(train_matrix.shape))\n",
    "print(\"Test matrix: \" + str(test_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sentiment_model = LogisticRegression(random_state=0).fit(train_matrix, train_data['sentiment'])\n",
    "zero_elem = (sentiment_model.coef_ > 0).sum()\n",
    "less_elem = (sentiment_model.coef_ <= 0).sum()\n",
    "total_val = zero_elem + less_elem\n",
    "print(\"Co-efficients with value more than 0: \" + str(zero_elem) + \" out of \" + str(total_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data = test_data[45:50]\n",
    "sample_test_data['review_clean'][235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores_sample = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function based on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_score(input_array):\n",
    "    result = []\n",
    "    for x in input_array:\n",
    "        if x >= 0:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "    return result\n",
    "check_score(scores_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_val = sentiment_model.predict_proba(sample_test_matrix)\n",
    "print(prob_val[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full data sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = sentiment_model.predict(test_matrix)\n",
    "final_scores_data = vectorizer.transform(test_data['review_clean'])\n",
    "final_score = sentiment_model.decision_function(final_scores_data)\n",
    "df = pd.DataFrame(final_score, columns = ['Score'])\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test_data\n",
    "df_test.reset_index(drop = True, inplace = True)\n",
    "df2 = pd.concat([df, df_test], axis = 1)\n",
    "df_export = df2.sort_values(by='Score', ascending=False)\n",
    "df_export.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data (Top & Bot 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top = df_export.head(20)\n",
    "df_top.to_csv('top20.csv')\n",
    "df_bottom = df_export.tail(20)\n",
    "df_bottom.to_csv('bottom20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy - Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scores dataframe shape: \" + str(df.shape))\n",
    "print(\"Test data sentiment as reference shape: \" + str(test_data.shape))\n",
    "accuracy_sentiment_model = sentiment_model.score(final_scores_data, test_data['sentiment'].values)\n",
    "print(\"Sentiment model accuracy:\\n\" + str(accuracy_sentiment_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary = significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])\n",
    "print(\"Train matrix special: \" + str(train_matrix_word_subset.shape))\n",
    "print(\"Test matrix special: \" + str(test_matrix_word_subset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Log-Reg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = LogisticRegression(random_state=0).fit(train_matrix_word_subset, train_data['sentiment'])\n",
    "zero_elem_simple = (simple_model.coef_ > 0).sum()\n",
    "print(zero_elem_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = simple_model.coef_\n",
    "arr2 = sentiment_model.coef_\n",
    "arr1 = arr1.reshape(-1, 1)\n",
    "arr2 = arr2.reshape(-1, 1)\n",
    "list1 = arr1.tolist()\n",
    "list2 = arr2.tolist()\n",
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-efficient dictionary for significant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the coefficients for 20 words used in model\n",
    "output_dict = dict(zip(significant_words, list1))\n",
    "setiment_dict = dict(zip(vectorizer.get_feature_names_out(), list2))\n",
    "#print(setiment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare two dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ndic(src, dest):\n",
    "    result = []\n",
    "    for skey, sval in src.items():\n",
    "        for nkey, nval in dest.items():\n",
    "            if skey == nkey:\n",
    "                result.append([skey, sval, nval])\n",
    "    return result\n",
    "\n",
    "new_list = compare_ndic(output_dict, setiment_dict)\n",
    "df_dict = pd.DataFrame(new_list, columns=['Word', 'Small', 'Sentiment'])\n",
    "df_dict.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare `train` & `test` accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sentiment_model = sentiment_model.score(final_scores_data, test_data['sentiment'].values)\n",
    "print(\"Sentiment model accuracy TRAINING data:\\n\" + str(accuracy_sentiment_model))\n",
    "\n",
    "accuracy_simple_model = simple_model.score(test_matrix_word_subset, test_data['sentiment'].values)\n",
    "print(\"Simple model accuracy TRAINING data:\\n\" + str(accuracy_simple_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Majority classifier accuracy should be:\\n\" + str(140259/(140259+26493)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
