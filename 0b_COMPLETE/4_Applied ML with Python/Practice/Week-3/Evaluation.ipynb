{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 178\n",
      "1 182\n",
      "2 177\n",
      "3 183\n",
      "4 181\n",
      "5 182\n",
      "6 181\n",
      "7 179\n",
      "8 174\n",
      "9 180\n"
     ]
    }
   ],
   "source": [
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target\n",
    "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
    "    print(class_name,class_count)\n",
    "\n",
    "y_binary_imbalanced = y.copy()\n",
    "y_binary_imbalanced[y_binary_imbalanced != 1] = 0\n",
    "#print(\"original labels: \", y[1:30])\n",
    "#print(\"new labels: \", y_binary_imbalanced[1:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVM Classifier & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (linear, C=1): \n",
      " [[402   5]\n",
      " [  5  38]]\n",
      "SVM (rbf, C=1): \n",
      " [[407   0]\n",
      " [  2  41]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state = 0)\n",
    "\n",
    "#linear kernel with C=1\n",
    "svm_linear = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "svm_pred = svm_linear.predict(X_test)\n",
    "confusion_svm_linear = confusion_matrix(y_test, svm_pred)\n",
    "print(\"SVM (linear, C=1): \\n\", confusion_svm_linear)\n",
    "\n",
    "#linear kernel with C=1\n",
    "svm_rbf = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "svm_pred = svm_rbf.predict(X_test)\n",
    "confusion_svm_rbf = confusion_matrix(y_test, svm_pred)\n",
    "print(\"SVM (rbf, C=1): \\n\", confusion_svm_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       407\n",
      "           1       1.00      0.95      0.98        43\n",
      "\n",
      "    accuracy                           1.00       450\n",
      "   macro avg       1.00      0.98      0.99       450\n",
      "weighted avg       1.00      1.00      1.00       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report: \\n\", classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation (accuracy) [0.91944444 0.98611111 0.97214485 0.97493036 0.96935933]\n",
      "Cross-validation (AUC) [0.9641871  0.9976571  0.99372205 0.99699002 0.98675611]\n",
      "Cross-validation (recall) [0.81081081 0.89189189 0.83333333 0.83333333 0.83333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target == 1\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "\n",
    "print('Cross-validation (accuracy)', cross_val_score(clf, X, y, cv=5))\n",
    "print('Cross-validation (AUC)', cross_val_score(clf, X, y, cv=5, scoring = 'roc_auc'))\n",
    "print('Cross-validation (recall)', cross_val_score(clf, X, y, cv=5, scoring = 'recall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GridSearchCV Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6a. Load Data and Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'gamma': 0.01}\n",
      "Grid best score (accuracy):  0.9205672587085226\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "svm_rbf = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "svm_pred = svm_rbf.predict(X_test)\n",
    "grid_values = {'gamma': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train, y_train)\n",
    "y_decision_fn_scores_acc = grid_clf_acc.decision_function(X_test) \n",
    "\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6b. Check the PARAMETERS (precision, recall, accuracy, f1) based on provided GAMMA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target == 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "for this_gamma in [0.01, 0.1, 1.0, 10.0]:\n",
    "    clf = SVC(gamma=this_gamma, C=1).fit(X_train, y_train)\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    print('Support Vector Classifier (rbf): gamma = {:.2f}'.format(this_gamma))\n",
    "    print('Accuracy: {}'.format(accuracy_score(y_test, clf_pred)))\n",
    "    print('Precision: {}'.format(precision_score(y_test, clf_pred)))\n",
    "    print('Recall: {}'.format(recall_score(y_test, clf_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Simple GridSearch Example Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best precision score:  1.0\n",
      "best parameters precision:  {'C': 1, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state = 0)\n",
    "best_score = 0\n",
    "#best_score_r = 0\n",
    "for gamma in [0.01, 0.1, 1, 10]:\n",
    "    for C in [0.01, 0.1, 1, 10]:\n",
    "        svm = SVC(gamma=gamma, C=C).fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        #score = svm.score(X_test, y_test)\n",
    "        best_score_precision = precision_score(y_test, y_pred)\n",
    "        #best_score_r = recall_score(y_test, y_pred)\n",
    "        if best_score_precision > best_score:\n",
    "            best_score = best_score_precision\n",
    "            best_parameters_p = {'C': C, 'gamma': gamma}\n",
    "print(\"best precision score: \", best_score)\n",
    "print(\"best parameters precision: \", best_parameters_p)\n",
    "#print(\"best recall score: \", best_score_r)\n",
    "#print(\"best parameters recall: \", best_parameters_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Logistic Regression Cross-validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores [0.98 0.96 0.98]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=3)\n",
    "print(\"Cross validation scores {}\".format(scores))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
